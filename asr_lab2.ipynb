{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04d0eabe",
   "metadata": {},
   "source": [
    "# Языковые модели\n",
    "\n",
    "Языковые модели играют важную роль в системах распознавания речи, помогая создавать более грамотные и лексически корректные тексты. В данной работе мы будем изучать нграмные языковые модели, которые позволяют довольно легко оценить вероятность и правдоподобность текста.\n",
    "\n",
    "В нграмной языковой модели, нграм - это последовательность из n слов в тексте. Например, в предложении \"по-моему мы сэкономим уйму времени если я сойду с ума прямо сейчас\", биграмами будут \"по-моему мы\", \"мы сэкономим\", \"сэкономим уйму\" итд. Языковые модели оценивают вероятность появления последовательности слов, исходя из статистики появления каждого из нграм в обучающей выборке.\n",
    "\n",
    "Порядком (order) нграм языковой модели называют максимальную длину нграм, которую учитывает модель. \n",
    "\n",
    "Практическая работа разделена на 2 части: \n",
    "1. Построение нграмой языковой модели - основная часть, 10 баллов\n",
    "1. Предсказание с помощью языковой модели - дополнительная часть, 6 балла\n",
    "\n",
    "\n",
    "\n",
    "Полезные сслыки:\n",
    "* arpa формат - https://cmusphinx.github.io/wiki/arpaformat/\n",
    "* обучающие материалы - resources/lab2/lecture13_ngrams_with_SRILM.pdf\n",
    "* обучающие материалы.2 - https://cjlise.github.io/machine-learning/N-Gram-Language-Model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd5c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1c1d7",
   "metadata": {},
   "source": [
    "# 1. Построение нграмной языковой модели. (10 баллов)\n",
    "\n",
    "\n",
    "Вероятность текста с помощью нграмной языковой модели можно вычислить по формуле: \n",
    "$$ P(w_1, w_2, .., w_n) = {\\prod{{P_{i=0}^{n}(w_i| w_{i-order}, .., w_{i-1})}}} $$\n",
    "\n",
    "В простом виде, при обучении нграмной языковой модели, чтобы рассчитать условную вероятность каждой нграмы, используется формула, основанная на количестве появлений нграмы в обучающей выборке. Формула выглядит следующим образом:\n",
    "$$ P(w_i| w_{i-order}, .., w_{i-1}) = {{count(w_{i-order}, .., w_{i})} \\over {count(w_{i-order},..., w_{i-1})}} $$\n",
    "\n",
    "Поскольку униграмы не содержат в себе какого-дибо контекста, вероятность униграмы можно посчитать поделив кол-во этой слова на общее количество слов в обучающей выборке. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5837fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в первую очередь нам понадобится подсчитать статистику по обучающей выборке \n",
    "def count_ngrams(train_text: List[str], order=3, bos=True, eos=True) -> Dict[Tuple[str], int]:\n",
    "    ngrams = defaultdict(int)\n",
    "    # TODO реализуйте функцию, которая подсчитывает все 1-gram 2-gram ... order-gram ngram'ы в тексте\n",
    "    texts = []\n",
    "    for i in range(len(train_text)):\n",
    "        texts.append(train_text[i].split())\n",
    "    print(texts[0])\n",
    "\n",
    "    for i in range(len(texts)):\n",
    "        if bos == True:\n",
    "            texts[i].insert(0, '<s>')\n",
    "        if eos == True:\n",
    "            texts[i].append('</s>')\n",
    "    o = order\n",
    "    '''\n",
    "    for m in range(len(texts)):\n",
    "        for word in texts[m]:\n",
    "            ngrams[(word,)] += 1\n",
    "        if order > 1:\n",
    "            for i in range(len(texts[m])):\n",
    "                try:\n",
    "                    ngrams[(texts[m][i], texts[m][i:i+order])] += 1\n",
    "                except:\n",
    "                    break\n",
    "    '''\n",
    "    for m in range(len(texts)):\n",
    "        for n in range(1, order + 1):\n",
    "            for i in range(len(texts[m]) - n + 1):\n",
    "                ngram = tuple(texts[m][i:i+n])\n",
    "                ngrams[ngram] += 1\n",
    "\n",
    "\n",
    "    print(dict(ngrams))\n",
    "    return dict(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd69d44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['привет', 'привет', 'как', 'дела']\n",
      "{('<s>',): 1, ('привет',): 2, ('как',): 1, ('дела',): 1, ('</s>',): 1}\n",
      "['привет', 'привет', 'как', 'дела']\n",
      "{('привет',): 2, ('как',): 1, ('дела',): 1, ('</s>',): 1}\n",
      "['привет', 'привет', 'как', 'дела']\n",
      "{('привет',): 2, ('как',): 1, ('дела',): 1}\n",
      "['привет', 'привет', 'как', 'дела']\n",
      "{('привет',): 2, ('как',): 1, ('дела',): 1, ('привет', 'привет'): 1, ('привет', 'как'): 1, ('как', 'дела'): 1}\n",
      "['привет', 'привет', 'привет', 'привет', 'привет', 'привет']\n",
      "{('привет',): 6, ('привет', 'привет'): 5}\n",
      "['практическое', 'сентября']\n",
      "{('<s>',): 3, ('практическое',): 2, ('сентября',): 2, ('</s>',): 3, ('<s>', 'практическое'): 1, ('практическое', 'сентября'): 1, ('сентября', '</s>'): 1, ('<s>', 'практическое', 'сентября'): 1, ('практическое', 'сентября', '</s>'): 1, ('<s>', 'практическое', 'сентября', '</s>'): 1, ('второе',): 1, ('занятие',): 1, ('пройдет',): 1, ('в',): 4, ('офлайне',): 2, ('32',): 3, ('12',): 2, ('часов',): 1, ('минуты',): 1, ('<s>', 'второе'): 1, ('второе', 'практическое'): 1, ('практическое', 'занятие'): 1, ('занятие', 'пройдет'): 1, ('пройдет', 'в'): 1, ('в', 'офлайне'): 2, ('офлайне', '32'): 1, ('32', 'сентября'): 1, ('сентября', 'в'): 1, ('в', '12'): 1, ('12', 'часов'): 1, ('часов', '32'): 1, ('32', 'минуты'): 1, ('минуты', '</s>'): 1, ('<s>', 'второе', 'практическое'): 1, ('второе', 'практическое', 'занятие'): 1, ('практическое', 'занятие', 'пройдет'): 1, ('занятие', 'пройдет', 'в'): 1, ('пройдет', 'в', 'офлайне'): 1, ('в', 'офлайне', '32'): 1, ('офлайне', '32', 'сентября'): 1, ('32', 'сентября', 'в'): 1, ('сентября', 'в', '12'): 1, ('в', '12', 'часов'): 1, ('12', 'часов', '32'): 1, ('часов', '32', 'минуты'): 1, ('32', 'минуты', '</s>'): 1, ('<s>', 'второе', 'практическое', 'занятие'): 1, ('второе', 'практическое', 'занятие', 'пройдет'): 1, ('практическое', 'занятие', 'пройдет', 'в'): 1, ('занятие', 'пройдет', 'в', 'офлайне'): 1, ('пройдет', 'в', 'офлайне', '32'): 1, ('в', 'офлайне', '32', 'сентября'): 1, ('офлайне', '32', 'сентября', 'в'): 1, ('32', 'сентября', 'в', '12'): 1, ('сентября', 'в', '12', 'часов'): 1, ('в', '12', 'часов', '32'): 1, ('12', 'часов', '32', 'минуты'): 1, ('часов', '32', 'минуты', '</s>'): 1, ('<s>', 'второе', 'практическое', 'занятие', 'пройдет'): 1, ('второе', 'практическое', 'занятие', 'пройдет', 'в'): 1, ('практическое', 'занятие', 'пройдет', 'в', 'офлайне'): 1, ('занятие', 'пройдет', 'в', 'офлайне', '32'): 1, ('пройдет', 'в', 'офлайне', '32', 'сентября'): 1, ('в', 'офлайне', '32', 'сентября', 'в'): 1, ('офлайне', '32', 'сентября', 'в', '12'): 1, ('32', 'сентября', 'в', '12', 'часов'): 1, ('сентября', 'в', '12', 'часов', '32'): 1, ('в', '12', 'часов', '32', 'минуты'): 1, ('12', 'часов', '32', 'минуты', '</s>'): 1, ('<s>', 'в'): 1, ('офлайне', 'в'): 1, ('в', '32'): 1, ('32', '12'): 1, ('12', '</s>'): 1, ('<s>', 'в', 'офлайне'): 1, ('в', 'офлайне', 'в'): 1, ('офлайне', 'в', '32'): 1, ('в', '32', '12'): 1, ('32', '12', '</s>'): 1, ('<s>', 'в', 'офлайне', 'в'): 1, ('в', 'офлайне', 'в', '32'): 1, ('офлайне', 'в', '32', '12'): 1, ('в', '32', '12', '</s>'): 1, ('<s>', 'в', 'офлайне', 'в', '32'): 1, ('в', 'офлайне', 'в', '32', '12'): 1, ('офлайне', 'в', '32', '12', '</s>'): 1}\n",
      "Test 1a passed\n"
     ]
    }
   ],
   "source": [
    "def test_count_ngrams():\n",
    "    assert count_ngrams(['привет привет как дела'], order=1, bos=True, eos=True) == {\n",
    "        ('<s>',): 1, \n",
    "        ('привет',): 2, \n",
    "        ('как',): 1, \n",
    "        ('дела',): 1, \n",
    "        ('</s>',): 1\n",
    "    }\n",
    "    assert count_ngrams(['привет привет как дела'], order=1, bos=False, eos=True) == {\n",
    "        ('привет',): 2, \n",
    "        ('как',): 1, \n",
    "        ('дела',): 1, \n",
    "        ('</s>',): 1\n",
    "    }\n",
    "    assert count_ngrams(['привет привет как дела'], order=1, bos=False, eos=False) == {\n",
    "        ('привет',): 2, \n",
    "        ('как',): 1, \n",
    "        ('дела',): 1\n",
    "    }\n",
    "    assert count_ngrams(['привет привет как дела'], order=2, bos=False, eos=False) == {\n",
    "        ('привет',): 2, \n",
    "        ('как',): 1, \n",
    "        ('дела',): 1,\n",
    "        ('привет', 'привет'): 1,\n",
    "        ('привет', 'как'): 1,\n",
    "        ('как', 'дела'): 1\n",
    "    }    \n",
    "    assert count_ngrams(['привет ' * 6], order=2, bos=False, eos=False) == {\n",
    "        ('привет',): 6, \n",
    "        ('привет', 'привет'): 5\n",
    "    }\n",
    "    result = count_ngrams(['практическое сентября',\n",
    "                           'второе практическое занятие пройдет в офлайне 32 сентября в 12 часов 32 минуты',\n",
    "                           'в офлайне в 32 12'], order=5)\n",
    "    assert result[('<s>',)] == 3\n",
    "    assert result[('32',)] == 3\n",
    "    assert result[('<s>', 'в', 'офлайне', 'в', '32')] == 1\n",
    "    assert result[('офлайне', 'в', '32', '12', '</s>')] == 1\n",
    "    print('Test 1a passed')\n",
    "    \n",
    "    \n",
    "test_count_ngrams()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e1865",
   "metadata": {},
   "source": [
    "\n",
    "Простой подход к вычислению вероятностей через количество нграм имеет существенный недостаток. Если в тексте встретится нграмма, которой не было в обучающей выборке, то вероятность всего текста будет равна нулю. \n",
    "\n",
    "Чтобы избежать данного недостатка, вводится специальное сглаживание - add-k сглаживание ([Additive, Laplace smoothing](https://en.wikipedia.org/wiki/Additive_smoothing)). Данная техника позволяет учитывать нграмы, не встретившиеся в обучающей выборке, и при этом не делает вероятность текста равной нулю.\n",
    "\n",
    "Формула сглаживания Лапласа выглядит следующим образом:\n",
    "\n",
    "$$ P(w_i| w_{i-order}, .., w_{i-1}) = {{count(w_{i-order}, .., w_{i}) + k} \\over {count(w_{i-order},..., w_{i-1}) + k*V}} $$\n",
    "\n",
    "Здесь V - количество слов в словаре, а k - гиперпараметр, который контролирует меру сглаживания. Как правило, значение k выбирается экспериментально, чтобы найти оптимальный баланс между учетом редких нграм и сохранением вероятности для часто встречающихся нграм.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cafb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция подсчета вероятности через количество со сглаживанием Лапласа\n",
    "def calculate_ngram_prob(ngram: Tuple[str], counts: Dict[Tuple[str], int], V=None, k=0) -> float:\n",
    "    # подсчитывет ngram со сглаживанием Лапласа\n",
    "    # TODO\n",
    "    if V is None:\n",
    "        # Вычисляем размер словаря как количество уникальных слов\n",
    "        V = len(set(gram[0] for gram in counts.keys() if len(gram) == 1))\n",
    "    \n",
    "    if len(ngram) == 1:\n",
    "        # Для униграмм: P(w) = count(w) / total_words\n",
    "        total_words = sum(count for gram, count in counts.items() if len(gram) == 1)\n",
    "        count_ngram = counts.get(ngram, 0)\n",
    "        return (count_ngram + k) / (total_words + k * V)\n",
    "    else:\n",
    "        # Для n-грамм: P(w_i|context) = count(ngram) / count(context)\n",
    "        context = ngram[:-1]\n",
    "        count_ngram = counts.get(ngram, 0)\n",
    "        count_context = counts.get(context, 0)\n",
    "        prob =  (count_ngram + k) / (count_context + k * V)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60b25d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['практическое', 'сентября']\n",
      "{('<s>',): 3, ('практическое',): 2, ('сентября',): 2, ('</s>',): 3, ('<s>', 'практическое'): 1, ('практическое', 'сентября'): 1, ('сентября', '</s>'): 1, ('<s>', 'практическое', 'сентября'): 1, ('практическое', 'сентября', '</s>'): 1, ('<s>', 'практическое', 'сентября', '</s>'): 1, ('второе',): 1, ('занятие',): 1, ('в',): 4, ('офлайне',): 2, ('32',): 3, ('12',): 2, ('часов',): 1, ('минуты',): 1, ('<s>', 'второе'): 1, ('второе', 'практическое'): 1, ('практическое', 'занятие'): 1, ('занятие', 'в'): 1, ('в', 'офлайне'): 2, ('офлайне', '32'): 1, ('32', 'сентября'): 1, ('сентября', 'в'): 1, ('в', '12'): 1, ('12', 'часов'): 1, ('часов', '32'): 1, ('32', 'минуты'): 1, ('минуты', '</s>'): 1, ('<s>', 'второе', 'практическое'): 1, ('второе', 'практическое', 'занятие'): 1, ('практическое', 'занятие', 'в'): 1, ('занятие', 'в', 'офлайне'): 1, ('в', 'офлайне', '32'): 1, ('офлайне', '32', 'сентября'): 1, ('32', 'сентября', 'в'): 1, ('сентября', 'в', '12'): 1, ('в', '12', 'часов'): 1, ('12', 'часов', '32'): 1, ('часов', '32', 'минуты'): 1, ('32', 'минуты', '</s>'): 1, ('<s>', 'второе', 'практическое', 'занятие'): 1, ('второе', 'практическое', 'занятие', 'в'): 1, ('практическое', 'занятие', 'в', 'офлайне'): 1, ('занятие', 'в', 'офлайне', '32'): 1, ('в', 'офлайне', '32', 'сентября'): 1, ('офлайне', '32', 'сентября', 'в'): 1, ('32', 'сентября', 'в', '12'): 1, ('сентября', 'в', '12', 'часов'): 1, ('в', '12', 'часов', '32'): 1, ('12', 'часов', '32', 'минуты'): 1, ('часов', '32', 'минуты', '</s>'): 1, ('<s>', 'в'): 1, ('офлайне', 'в'): 1, ('в', '32'): 1, ('32', '12'): 1, ('12', '</s>'): 1, ('<s>', 'в', 'офлайне'): 1, ('в', 'офлайне', 'в'): 1, ('офлайне', 'в', '32'): 1, ('в', '32', '12'): 1, ('32', '12', '</s>'): 1, ('<s>', 'в', 'офлайне', 'в'): 1, ('в', 'офлайне', 'в', '32'): 1, ('офлайне', 'в', '32', '12'): 1, ('в', '32', '12', '</s>'): 1}\n",
      "Test 1.b passed\n"
     ]
    }
   ],
   "source": [
    "def test_calculate_ngram_prob():\n",
    "    counts = count_ngrams(['практическое сентября',\n",
    "                           'второе практическое занятие в офлайне 32 сентября в 12 часов 32 минуты',\n",
    "                           'в офлайне в 32 12'], order=4)\n",
    "    assert calculate_ngram_prob(('в', 'офлайне'), counts) == 0.5\n",
    "    assert calculate_ngram_prob(('в', ), counts) == 4/25\n",
    "    assert calculate_ngram_prob(('в', ), counts, k=0.5) == (4+0.5)/(25+0.5*12)\n",
    "    assert calculate_ngram_prob(('в', 'офлайне', 'в', '32'), counts) == 1.0\n",
    "    assert calculate_ngram_prob(('в', 'офлайне'), counts, k=1) == 0.1875\n",
    "    assert calculate_ngram_prob(('в', 'офлайне'), counts, k=0.5) == 0.25\n",
    "    assert calculate_ngram_prob(('в', 'онлайне'), counts, k=0) == 0.0\n",
    "    assert calculate_ngram_prob(('в', 'онлайне'), counts, k=1) == 0.0625\n",
    "    assert calculate_ngram_prob(('в', 'офлайне'), counts, k=0.5) == 0.25\n",
    "\n",
    "    print(\"Test 1.b passed\")\n",
    "    \n",
    "\n",
    "test_calculate_ngram_prob()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da494bf0",
   "metadata": {},
   "source": [
    "Основной метрикой язковых моделей является перплексия. \n",
    "\n",
    "Перплексия  — безразмерная величина, мера того, насколько хорошо распределение вероятностей предсказывает выборку. Низкий показатель перплексии указывает на то, что распределение вероятности хорошо предсказывает выборку.\n",
    "\n",
    "$$ ppl = {P(w_1, w_2 ,..., w_N)^{- {1} \\over {N}}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bd1f2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Языковая модель \n",
    "class NgramLM:\n",
    "    def __init__(self, order=3, bos=True, eos=True, k=1, predefined_vocab=None):\n",
    "        self.order = order\n",
    "        self.eos = eos\n",
    "        self.bos = bos\n",
    "        self.k = k\n",
    "        self.vocab = predefined_vocab\n",
    "        self.ngrams_count = None\n",
    "        \n",
    "    @property\n",
    "    def V(self) -> int:\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def fit(self, train_text: List[str]) -> None:\n",
    "        # TODO\n",
    "        # Подсчет vocab и ngrams_count по обучающей выборке\n",
    "        self.ngrams_count = count_ngrams(train_text, order=self.order, bos=self.bos, eos=self.eos)\n",
    "        \n",
    "        # Построение словаря\n",
    "        if self.vocab is None:\n",
    "            self.vocab = set()\n",
    "            for text in train_text:\n",
    "                words = text.split()\n",
    "                self.vocab.update(words)\n",
    "            if self.bos:\n",
    "                self.vocab.add('<s>')\n",
    "            if self.eos:\n",
    "                self.vocab.add('</s>')\n",
    "        \n",
    "        # Подсчет общего количества униграмм\n",
    "        self._total_unigrams = sum(count for gram, count in self.ngrams_count.items() if len(gram) == 1)\n",
    "    \n",
    "    def predict_ngram_log_proba(self, ngram: Tuple[str]) -> float:\n",
    "        # TODO \n",
    "        # считаем логарифм вероятности конкретной нграмы\n",
    "        if len(ngram) == 1:\n",
    "            # Unigram case\n",
    "            count_ngram = self.ngrams_count.get(ngram, 0)\n",
    "            prob = (count_ngram + self.k) / (self._total_unigrams + self.k * self.V)\n",
    "        else:\n",
    "            # Higher order n-gram\n",
    "            context = ngram[:-1]\n",
    "            count_ngram = self.ngrams_count.get(ngram, 0)\n",
    "            count_context = self.ngrams_count.get(context, 0)\n",
    "            prob = (count_ngram + self.k) / (count_context + self.k * self.V)\n",
    "        \n",
    "        return np.log(prob) if prob > 0 else -np.inf\n",
    "           \n",
    "    def predict_log_proba(self, words: List[str]) -> float:\n",
    "        if self.bos:\n",
    "            words = ['<s>'] + words\n",
    "        if self.eos:\n",
    "            words = words + ['</s>']\n",
    "        logprob = 0\n",
    "        # TODO\n",
    "        for i in range(len(words)):\n",
    "            # Определяем контекст\n",
    "            context_start = max(0, i - self.order + 1)\n",
    "            context = words[context_start:i]\n",
    "            ngram = tuple(context + [words[i]])\n",
    "            \n",
    "            logprob += self.predict_ngram_log_proba(ngram)\n",
    "        # применяем chain rule, чтобы посчитать логарифм вероятности всей строки\n",
    "        return logprob\n",
    "        \n",
    "    def ppl(self, text: List[str]) -> float:\n",
    "        #TODO \n",
    "        # подсчет перплексии\n",
    "        # Для того, чтобы ваш код был численно стабильным, \n",
    "        #    не считайте формулу напрямую, а воспользуйтесь переходом к логарифмам вероятностей\n",
    "        #\n",
    "        if not text or text == ['']:\n",
    "            words = []\n",
    "        else:\n",
    "            words = text[0].split() if isinstance(text[0], str) else text\n",
    "            \n",
    "        logprob = self.predict_log_proba(words)\n",
    "        \n",
    "        # Calculate number of words (for normalization)\n",
    "        N = len(words)\n",
    "        if self.bos:\n",
    "            N += 1\n",
    "        if self.eos:\n",
    "            N += 1\n",
    "            \n",
    "        if N == 0:\n",
    "            return float('inf')\n",
    "            \n",
    "        perplexity = np.exp(-logprob / N)\n",
    "        return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb0bfe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['по-моему', 'мы', 'сэкономим', 'уйму', 'времени', 'если', 'я', 'сойду', 'с', 'ума', 'прямо', 'сейчас']\n",
      "{('<s>',): 3, ('по-моему',): 3, ('мы',): 3, ('сэкономим',): 3, ('уйму',): 3, ('времени',): 3, ('если',): 3, ('я',): 3, ('сойду',): 3, ('с',): 3, ('ума',): 3, ('прямо',): 2, ('сейчас',): 3, ('</s>',): 3, ('<s>', 'по-моему'): 1, ('по-моему', 'мы'): 2, ('мы', 'сэкономим'): 3, ('сэкономим', 'уйму'): 3, ('уйму', 'времени'): 3, ('времени', 'если'): 2, ('если', 'я'): 3, ('я', 'сойду'): 2, ('сойду', 'с'): 3, ('с', 'ума'): 3, ('ума', 'прямо'): 2, ('прямо', 'сейчас'): 2, ('сейчас', '</s>'): 1, ('<s>', 'если'): 1, ('сейчас', 'по-моему'): 1, ('времени', '</s>'): 1, ('<s>', 'мы'): 1, ('я', 'сейчас'): 1, ('сейчас', 'сойду'): 1, ('ума', 'по-моему'): 1, ('по-моему', '</s>'): 1}\n"
     ]
    }
   ],
   "source": [
    "def test_lm():\n",
    "    train_data = [\"по-моему мы сэкономим уйму времени если я сойду с ума прямо сейчас\",\n",
    "                  \"если я сойду с ума прямо сейчас по-моему мы сэкономим уйму времени\",\n",
    "                  \"мы сэкономим уйму времени если я сейчас сойду с ума по-моему\"]\n",
    "    global lm\n",
    "    lm = NgramLM(order=2)\n",
    "    lm.fit(train_data)\n",
    "    assert lm.V == 14\n",
    "    assert np.isclose(lm.predict_log_proba(['мы']), lm.predict_log_proba([\"если\"]))\n",
    "    assert lm.predict_log_proba([\"по-моему\"]) > lm.predict_log_proba([\"если\"]) \n",
    "    \n",
    "    gt = ((3+1)/(41 + 14) * 1/(3+14))**(-1/2)\n",
    "    ppl = lm.ppl([''])\n",
    "    assert  np.isclose(ppl, gt), f\"{ppl=} {gt=}\"\n",
    "    \n",
    "    gt = ((3+1)/(41 + 14) * 1/(3+14) * 1/(14)) ** (-1/3)\n",
    "    ppl = lm.ppl(['ЧТО'])\n",
    "    assert  np.isclose(ppl, gt), f\"{ppl=} {gt=}\"\n",
    "    \n",
    "    test_data = [\"по-моему если я прямо сейчас сойду с ума мы сэкономим уйму времени\"]\n",
    "    ppl = lm.ppl(test_data)\n",
    "    assert round(ppl, 2) == 7.33, f\"{ppl}\"\n",
    "test_lm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edafa0a2",
   "metadata": {},
   "source": [
    "# 2. Предсказания с помощью языковой модели (6 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85d2eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(lm: NgramLM, prefix: List[str], topk=4):\n",
    "    # TODO реализуйте функцию, которая предсказывает продолжение фразы. \n",
    "    # верните topk наиболее вероятных продолжений фразы prefix\n",
    "    context = prefix[-(lm.order-1):] if len(prefix) >= lm.order-1 else prefix\n",
    "    \n",
    "    candidates = []\n",
    "    for word in lm.vocab:\n",
    "        if word in ['<s>', '</s>']:\n",
    "            continue\n",
    "            \n",
    "        ngram = tuple(context + [word])\n",
    "        log_prob = lm.predict_ngram_log_proba(ngram)\n",
    "        candidates.append((word, log_prob))\n",
    "    \n",
    "    # Сортируем по убыванию вероятности\n",
    "    candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "    word = candidates[:topk]\n",
    "    return word\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4846b",
   "metadata": {},
   "source": [
    "Попробуйте обучить ngram языковую модель на нескольких стихотворениях. Не забудьте трансформировать стихотворение в удобный для ngram модели формат (как сделать так, чтобы модель моделировала рифму?). \n",
    "Попробуйте сгенерировать продолжение для стихотворения с помощью такой языковой модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "107862fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['я', 'помню', 'чудное', 'мгновенье', 'передо', 'мной', 'явилась', 'ты']\n",
      "{('<s>',): 4, ('я',): 1, ('помню',): 1, ('чудное',): 1, ('мгновенье',): 1, ('передо',): 1, ('мной',): 1, ('явилась',): 1, ('ты',): 2, ('</s>',): 4, ('<s>', 'я'): 1, ('я', 'помню'): 1, ('помню', 'чудное'): 1, ('чудное', 'мгновенье'): 1, ('мгновенье', 'передо'): 1, ('передо', 'мной'): 1, ('мной', 'явилась'): 1, ('явилась', 'ты'): 1, ('ты', '</s>'): 1, ('мороз',): 1, ('и',): 1, ('солнце',): 1, ('день',): 1, ('чудесный',): 1, ('еще',): 1, ('дремлешь',): 1, ('друг',): 1, ('прелестный',): 1, ('<s>', 'мороз'): 1, ('мороз', 'и'): 1, ('и', 'солнце'): 1, ('солнце', 'день'): 1, ('день', 'чудесный'): 1, ('чудесный', 'еще'): 1, ('еще', 'ты'): 1, ('ты', 'дремлешь'): 1, ('дремлешь', 'друг'): 1, ('друг', 'прелестный'): 1, ('прелестный', '</s>'): 1, ('люблю',): 1, ('грозу',): 1, ('в',): 2, ('начале',): 1, ('мая',): 1, ('когда',): 1, ('весенний',): 1, ('первый',): 1, ('гром',): 1, ('<s>', 'люблю'): 1, ('люблю', 'грозу'): 1, ('грозу', 'в'): 1, ('в', 'начале'): 1, ('начале', 'мая'): 1, ('мая', 'когда'): 1, ('когда', 'весенний'): 1, ('весенний', 'первый'): 1, ('первый', 'гром'): 1, ('гром', '</s>'): 1, ('зима',): 1, ('недаром',): 1, ('злится',): 1, ('прошла',): 1, ('ее',): 1, ('пора',): 1, ('весна',): 1, ('окно',): 1, ('стучится',): 1, ('<s>', 'зима'): 1, ('зима', 'недаром'): 1, ('недаром', 'злится'): 1, ('злится', 'прошла'): 1, ('прошла', 'ее'): 1, ('ее', 'пора'): 1, ('пора', 'весна'): 1, ('весна', 'в'): 1, ('в', 'окно'): 1, ('окно', 'стучится'): 1, ('стучится', '</s>'): 1}\n",
      "Продолжение для 'люблю грозу':\n",
      "  в: 0.0769\n",
      "  весна: 0.0256\n",
      "  зима: 0.0256\n",
      "Перплексия для тестового текста: 20.21\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "# Пример с стихотворениями\n",
    "poems = [\n",
    "    \"я помню чудное мгновенье передо мной явилась ты\",\n",
    "    \"мороз и солнце день чудесный еще ты дремлешь друг прелестный\",\n",
    "    \"люблю грозу в начале мая когда весенний первый гром\",\n",
    "    \"зима недаром злится прошла ее пора весна в окно стучится\"\n",
    "]\n",
    "\n",
    "# Обучаем модель\n",
    "lm = NgramLM(order=2, k=0.5)\n",
    "lm.fit(poems)\n",
    "\n",
    "# Предсказываем продолжение\n",
    "prefix = [\"люблю\", \"грозу\"]\n",
    "predictions = predict_next_word(lm, prefix, topk=3)\n",
    "print(\"Продолжение для 'люблю грозу':\")\n",
    "for word, log_prob in predictions:\n",
    "    print(f\"  {word}: {np.exp(log_prob):.4f}\")\n",
    "\n",
    "# Вычисляем перплексию\n",
    "test_poem = [\"зима\", \"недаром\", \"злится\"]\n",
    "ppl = lm.ppl(test_poem)\n",
    "print(f\"Перплексия для тестового текста: {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa1fa175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный текст: люблю грозу в начале мая когда весенний первый гром\n"
     ]
    }
   ],
   "source": [
    "def generate_text(lm: NgramLM, start_words: List[str], length=10):\n",
    "    generated = start_words.copy()\n",
    "    \n",
    "    for _ in range(length):\n",
    "        next_word_candidates = predict_next_word(lm, generated, topk=1)\n",
    "        if not next_word_candidates:\n",
    "            break\n",
    "        next_word = next_word_candidates[0][0]\n",
    "        generated.append(next_word)\n",
    "        \n",
    "    return ' '.join(generated)\n",
    "\n",
    "# Генерация текста\n",
    "generated = generate_text(lm, [\"люблю\"], length=8)\n",
    "print(f\"Сгенерированный текст: {generated}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itmo_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
